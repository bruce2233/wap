<!doctype html>
<html lang="zh-Hans">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>研究生中文 | Attention Is All You Need</title>
  <meta name="description" content="面向研究生读者的 Attention Is All You Need 技术解读。" />
  <link rel="preconnect" href="https://fonts.googleapis.com" />
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
  <link href="https://fonts.googleapis.com/css2?family=Noto+Sans+SC:wght@300;400;500;600;700&family=Space+Grotesk:wght@400;500;600;700&display=swap" rel="stylesheet" />
  <link rel="stylesheet" href="/papers/attention-is-all-you-need/styles.css" />
</head>
<body>
  <div class="backdrop" aria-hidden="true">
    <div class="orb orb-one"></div>
    <div class="orb orb-two"></div>
    <div class="orb orb-three"></div>
  </div>

  <div class="page">
    <header class="topbar">
      <div class="brand">
        <span>WAP PAPER</span>
        <h1>Attention Is All You Need</h1>
      </div>
      <nav class="nav-links">
        <a href="/">WAP Index</a>
        <a href="/papers/attention-is-all-you-need/index.html">All Versions</a>
        <a href="/papers/attention-is-all-you-need/hs-en.html">HS EN</a>
        <a href="/papers/attention-is-all-you-need/grad-en.html">Grad EN</a>
        <a href="/papers/attention-is-all-you-need/hs-zh.html">高中</a>
      </nav>
    </header>

    <section class="hero reveal">
      <div class="hero-card primary">
        <h2>技术要点</h2>
        <p>Transformer 用纯注意力构建序列到序列模型：编码器与解码器都由多头自注意力和逐位置前馈网络组成，摆脱 RNN/CNN 的顺序依赖，实现高并行训练。</p>
        <div class="badge-row">
          <span class="badge">研究生 · 中文</span>
          <span class="badge">自注意力</span>
          <span class="badge">编码器-解码器</span>
        </div>
        <div class="attention-map"></div>
      </div>
      <div class="hero-card">
        <h2>论文信息</h2>
        <div class="fact-grid">
          <div class="fact-item">作者：Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin</div>
          <div class="fact-item">日期：2017-06-12</div>
          <div class="fact-item">会议：NeurIPS (NIPS) 2017</div>
          <div class="fact-item">arXiv：1706.03762</div>
          <div class="fact-item">DOI：10.48550/arXiv.1706.03762</div>
        </div>
      </div>
    </section>

    <section id="problem" class="section reveal">
      <h3>Problem setup / 背景</h3>
      <p>序列模型如果依赖 RNN 或 CNN，会在长距离依赖建模和并行效率上受限。论文提出问题：是否可以只用注意力机制完成机器翻译并达到更好效果？</p>
    </section>

    <section id="method" class="section reveal">
      <h3>Method / 方法</h3>
      <p>Transformer 的核心是注意力。每个输出是对值向量的加权求和，权重由查询和键的相似度计算：</p>
      <div class="formula">Attention(Q, K, V) = softmax(QK^T / sqrt(d_k)) V</div>
      <ul>
        <li><strong>多头注意力：</strong>将 Q、K、V 投影到 h 个子空间并行计算，再拼接输出。</li>
        <li><strong>编码器层：</strong>多头自注意力 + 逐位置前馈网络。</li>
        <li><strong>解码器层：</strong>遮挡自注意力 + 编码器-解码器注意力 + 前馈网络。</li>
        <li><strong>残差与层归一化：</strong>每个子层外接残差与 LayerNorm。</li>
        <li><strong>位置编码：</strong>使用不同频率的正弦/余弦函数注入顺序信息。</li>
      </ul>
    </section>

    <section id="experiments" class="section reveal">
      <h3>Experiments & Results / 实验与结果</h3>
      <p>Transformer 在 WMT14 翻译任务上达到当时 SOTA，并在英文句法分析上保持竞争力，训练效率高。</p>
      <div class="metric-grid">
        <div class="metric-card">
          <h4>WMT14 英→德</h4>
          <span>BLEU 28.4，比之前最好系统高 2+ BLEU。</span>
        </div>
        <div class="metric-card">
          <h4>WMT14 英→法</h4>
          <span>BLEU 41.8，单模型新纪录。</span>
        </div>
        <div class="metric-card">
          <h4>训练成本</h4>
          <span>报告主模型在 8 块 GPU 上约 3.5 天。</span>
        </div>
        <div class="metric-card">
          <h4>句法分析</h4>
          <span>英文句法分析任务上表现具有竞争力。</span>
        </div>
      </div>
    </section>

    <section id="limitations" class="section reveal">
      <h3>Limitations / 局限</h3>
      <p class="note">论文未单独讨论局限。实验主要覆盖机器翻译与英文句法分析，其他任务或超长上下文的泛化仍需更多证据。</p>
    </section>

    <section id="resources" class="section reveal">
      <h3>Resources / 资源</h3>
      <div class="resource-list">
        <div class="resource">
          <span>论文（arXiv）</span>
          <a href="https://arxiv.org/abs/1706.03762" target="_blank" rel="noreferrer">Open</a>
        </div>
        <div class="resource">
          <span>PDF</span>
          <a href="https://arxiv.org/pdf/1706.03762.pdf" target="_blank" rel="noreferrer">Download</a>
        </div>
        <div class="resource">
          <span>DOI</span>
          <a href="https://doi.org/10.48550/arXiv.1706.03762" target="_blank" rel="noreferrer">10.48550/arXiv.1706.03762</a>
        </div>
        <div class="resource">
          <span>NeurIPS 页面</span>
          <a href="https://research.google/pubs/attention-is-all-you-need/" target="_blank" rel="noreferrer">Publication</a>
        </div>
        <div class="resource">
          <span>Tensor2Tensor 实现</span>
          <a href="https://github.com/tensorflow/tensor2tensor" target="_blank" rel="noreferrer">Code</a>
        </div>
      </div>
    </section>

    <section id="citation" class="section reveal">
      <h3>Suggested citation / 推荐引用</h3>
      <div class="citation">
        Vaswani, Ashish, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017. “Attention Is All You Need.” arXiv:1706.03762. https://doi.org/10.48550/arXiv.1706.03762.
      </div>
      <button class="copy-btn" type="button" data-copy="Vaswani, Ashish, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017. Attention Is All You Need. arXiv:1706.03762. https://doi.org/10.48550/arXiv.1706.03762.">Copy citation</button>
    </section>

    <footer class="footer">这是研究生中文版本。</footer>
  </div>

  <script src="/papers/attention-is-all-you-need/script.js"></script>
</body>
</html>
