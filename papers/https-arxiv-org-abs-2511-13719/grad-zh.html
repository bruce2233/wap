<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Doc-Researcher (研究生版) | WAP</title>
  <link rel="stylesheet" href="/papers/https-arxiv-org-abs-2511-13719/styles.css" />
  <link href="https://fonts.googleapis.com/css2?family=Noto+Sans+SC:wght@300;400;500;700&display=swap" rel="stylesheet" />
</head>
<body>
  <div class="backdrop" aria-hidden="true"></div>
  <div class="page">
    <header class="hero reveal">
      <div class="eyebrow">学术 / 研究生版</div>
      <h1>Doc-Researcher：破解复杂文档多模态处理的瓶颈</h1>
      <p class="subtitle">技术深潜：深度多模态解析、自适应检索与代理式证据合成。</p>
    </header>

    <nav class="section-nav reveal">
      <a href="#motivation">动机</a>
      <a href="#parsing">深度解析</a>
      <a href="#retrieval">检索架构</a>
      <a href="#agents">代理流</a>
      <a href="#bench">评测体系</a>
      <a href="#results">实验结果</a>
    </nav>

    <section id="motivation" class="chapter reveal" data-section>
      <h2>研究动机与问题定义</h2>
      <p>当前的“深度研究 (Deep Research)”系统（如基于 LLM 的系统）主要局限于文本类 Web 数据。在专业领域，核心知识往往以<strong>高度结构化的多模态文档</strong>（PDF/扫描件）形式存在。传统的 RAG（检索增强生成）流程在这种场景下通常会失效，因为它们将文档“扁平化”，丢失了图表轴线、视觉层次或表格嵌套关系等关键视觉语义。</p>
    </section>

    <section id="parsing" class="chapter reveal" data-section>
      <h2>一、深度多模态解析引擎</h2>
      <p>Doc-Researcher 采用了一种能够保持<strong>多模态完整性</strong>的解析引擎。它建立了多层级的表示体系：</p>
      <ul>
        <li><strong>块级 (Chunk-level)：</strong> 捕捉局部上下文，包括行内公式和数学符号。</li>
        <li><strong>模块级 (Block-level)：</strong> 遵循逻辑视觉边界（例如带有标题的特定图表）。</li>
        <li><strong>文档级 (Document-level)：</strong> 维护全局的排版结构与语义。</li>
      </ul>
      <div class="callout">核心创新：该系统将视觉元素映射到文本描述，同时保留原始像素特征，用于视觉中心路径的检索。</div>
    </section>

    <section id="retrieval" class="chapter reveal" data-section>
      <h2>二、系统化的混合检索架构</h2>
      <p>Doc-Researcher 支持三种检索范式：</p>
      <ol>
        <li><strong>纯文本检索 (Text-only)：</strong> 对文本块执行标准语义搜索。</li>
        <li><strong>纯视觉检索 (Vision-only)：</strong> 基于视觉相似度直接检索文档区域。</li>
        <li><strong>混合检索 (Hybrid)：</strong> 结合文本与视觉信号，并具备<em>动态粒度选择</em>能力——根据查询的模糊性在细粒度块或宏观文档上下文中自动切换。</li>
      </ol>
    </section>

    <section id="agents" class="chapter reveal" data-section>
      <h2>三、迭代多智能体工作流</h2>
      <p>不同于单次检索，Doc-Researcher 引入了代理循环：</p>
      <ul>
        <li><strong>规划者 (Planner)：</strong> 将复杂的多跳查询拆分为子任务。</li>
        <li><strong>搜寻者 (Searcher)：</strong> 执行混合检索寻找候选证据。</li>
        <li><strong>精炼者 (Refiner)：</strong> 评估检索证据，决定是否需要继续搜索（迭代式累计）。</li>
        <li><strong>合成者 (Synthesizer)：</strong> 整合多模态证据，生成带有引用的最终答案。</li>
      </ul>
    </section>

    <section id="bench" class="chapter reveal" data-section>
      <h2>M4DocBench 高难度评测</h2>
      <p>为了全面评估上述能力，作者提出了 <strong>M4DocBench</strong>（多模态、多跳、多文档、多轮对话）。它包含由专家标注的 158 个高难度问题，涉及 304 份复杂文档。该基准要求模型能够跨文件、跨模态“连接线索”。</p>
    </section>

    <section id="results" class="chapter reveal" data-section>
      <h2>实验表现</h2>
      <div class="highlight-row">
        <div class="highlight-card">
          <strong>直接对比</strong>
          <div>Doc-Researcher 准确率达到 50.6%，比目前最先进的基准系统（~15%）高出 3.4 倍。</div>
        </div>
        <div class="highlight-card">
          <strong>消融实验</strong>
          <div>移除“视觉语义”组件导致性能跌幅最大，证明了布局信息在文档理解中的核心地位。</div>
        </div>
      </div>
    </section>

    <footer class="footer">WAP - 为深度文档研究提供严谨洞察。</footer>
  </div>
  <script src="/papers/https-arxiv-org-abs-2511-13719/script.js"></script>
</body>
</html>
